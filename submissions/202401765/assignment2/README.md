# HUFS (Language & AI 융합학부) - 기계학습의이해 (2025-2)

# MNIST 분류 실험 결과

## MNIST 기본 모델 성능

- **기본 모델 정확도 (Baseline):** 96.65% 
- **훈련 시간:** 약 1분 30초
- **과적합 정도:**  훈련 97.07% - 테스트 96.65% = 약 0.42% 차이

---
## 실험 결과

### 실험 1: 하이퍼파라미터 튜닝 (학습률 1e-4)

- **변경사항:** 학습률 (`learning_rate`)을 `1e-3` (0.001)에서 **`1e-4` (0.0001)**로 변경
- **결과:** 최종 테스트 정확도 **92.68%**
- **분석:** 학습률을 너무 낮추자 3번의 에포크 동안 모델이 충분히 수렴하지 못하여 기본 모델보다 성능이 크게 하락

## # 실험 2: 모델 구조 개선 (예정)

- **계획:** 은닉층 뒤에 **`nn.Dropout(0.5)`**를 추가하여 과적합을 방지하는 실험을 진행할 예정
- **변경사항:** 첫 번째 은닉층 뒤에 nn.Dropout(0.5) 추가
- **결과:** 최종 테스트 정확도 **96.00%**
- **분석:** Dropout 적용 후 테스트 정확도는 기본 모델보다 약간 하락. 이는 기본 모델이 이미 안정적이었기 때문에, Dropout이 불필요한 규제(Regularization)로 작용했을 수 있음

---

## 결론 및 인사이트
- **가장 효과적인 개선 방법**: 두 가지 실험 중 기본 모델보다 성능이 향상된 것은 없었음. 기본 모델 설정이 현재 실험 구성(3 에포크)에서는 가장 효율적

- **관찰된 패턴**: 간단한 MLP 모델임에도 불구하고 MNIST 데이터셋에 대해 매우 안정적이며 높은 초기 성능(>96%)을 보였음. 튜닝 시에는 수렴 시간(에포크 수)과 규제 강도를 신중하게 고려해야 함을 확인

- **추가 개선 아이디어**:

  **에포크 수 증가**: 학습률이 낮거나 모델 복잡도가 높은 경우, 에포크 수를 10회 또는 20회로 늘려 수렴 여부를 관찰해야 할듯

  **CNN으로 전환**: 이미지 분류 성능을 99% 이상으로 높이기 위해 MLP보다 강력한 Convolutional Neural Network (CNN) 구조로 전환하는 것이 가장 확실한 개선 방안입니다.(제미나이 제안 방법)
